
//					Copyright Gavin Band 2008 - 2012.
// Distributed under the Boost Software License, Version 1.0.
//		(See accompanying file LICENSE_1_0.txt or copy at
//					http://www.boost.org/LICENSE_1_0.txt)

#include "../package_revision_autogenerated.hpp"

//#include <unordered_map>
//#include <unordered_set>
//#include <set>
#include <memory>
#include <mutex>
#include <algorithm>
//#include <boost/ptr_container/ptr_vector.hpp>
#include <boost/filesystem.hpp>
#include <boost/noncopyable.hpp>
#include <boost/timer.hpp>
//#include <boost/lockfree/queue.hpp>
#include <chrono>
#include <thread>

// seqlib
#include "SeqLib/RefGenome.h"
#include "SeqLib/BamReader.h"
#include "SeqLib/GenomicRegionCollection.h"
#include "SeqLib/GenomicRegion.h"
//#include "SeqLib/BWAWrapper.h"

namespace seqlib = SeqLib;
// namespace bt = BamTools ;

#include "appcontext/appcontext.hpp"
#include "genfile/GenomePositionRange.hpp"
#include "genfile/FileUtils.hpp"
#include "genfile/string_utils/string_utils.hpp"
#include "genfile/string_utils/slice.hpp"
#include "genfile/Error.hpp"
#include "genfile/kmer/KmerHashIterator.hpp"
#include "statfile/BuiltInTypeStatSink.hpp"

#include "jellyfish/jellyfish.hpp"

#include "parallel_hashmap/phmap.h"
#include "parallel_hashmap/meminfo.h"
#include "concurrentqueue/concurrentqueue.h"

/*
#include <sys/types.h>
#include <sys/sysinfo.h>
*/

#define DEBUG 0

namespace globals {
	std::string const program_name = "classify-kmers" ;
	std::string const program_version = package_version ;
	std::string const program_revision = std::string( package_revision ).substr( 0, 7 ) ;
}

namespace {
	typedef phmap::parallel_flat_hash_map< uint64_t, uint16_t > ParallelHashMap ;
	struct identity_hash {
		std::size_t operator()( uint64_t const value ) { return value ; }
	} ;
	typedef phmap::flat_hash_set<uint64_t> FlatHashSet ;

	typedef phmap::parallel_flat_hash_set<
		uint64_t,
		phmap::priv::hash_default_hash<uint64_t>,
		phmap::priv::hash_default_eq<uint64_t>,
		phmap::priv::Allocator<uint64_t>,
		5, // 2^(this number) of submaps
		std::mutex
	> ParallelFlatHashSet ;

	typedef jellyfish::cooperative::hash_counter<jellyfish::mer_dna> JellyfishHashMap ; 

	// HashSet in actual use.
	//typedef FlatHashSet HashSet ;
	typedef ParallelFlatHashSet HashSet ;

	typedef moodycamel::ConcurrentQueue< uint64_t > Queue ;

	template< typename HashMap >
	void classify_threaded(
		std::size_t const k,
		Queue* queue,
		HashMap* result,
		std::size_t const thread_index,
		std::atomic< int >* quit
	) {
#if DEBUG
		std::cerr << "(thread " << thread_index << "): Starting...\n" ;
#endif	
		std::size_t count = 0 ;
		uint64_t elt ;
		while( !(*quit) ) {
#if DEBUG > 1
			std::cerr << "!! (" << thread_index << ", " << std::this_thread::get_id() << "): " << queue << ".\n" ;
#endif
			bool popped = queue->try_dequeue( elt ) ;
#if DEBUG > 1
			std::cerr
				<< "(thread " << thread_index << ") "
				<< "!! " << ( popped ? "popped" : "nothing to pop" )
				<< ", queue approx size = " << queue->size_approx()
				<< ".\n" ;
#endif
			if( popped ) {
				result->insert( elt ) ;
				++count ;
				if( (count & 0xFFFFFFF) == 0 ) {
					std::cerr << "(thread " << thread_index << ") ++ Added " << count << " kmers.\n" ;
				}
			} else {
				// nothing to pop, sleep to allow queue to fill.
				std::this_thread::sleep_for( std::chrono::microseconds(10) ) ;
			}
		}
#if DEBUG
		std::cerr
			<< "(thread " << thread_index << "): ++ Added "
			<< count << " kmers in total.\n" ;
		std::cerr << "(thread " << thread_index << "): ++ Ending...\n" ;
#endif
	}
}

struct AssessPositionOptionProcessor: public appcontext::CmdLineOptionProcessor
{
public:
	std::string get_program_name() const { return globals::program_name ; }

	void declare_options( appcontext::OptionProcessor& options ) {
		// Meta-options
		options.set_help_option( "-help" ) ;
		
		options.declare_group( "Input / output file options" ) ;
		options[ "-jf" ]
			.set_description( "Path of jellyfish file to load kmers from." )
			.set_takes_values_until_next_option()
			.set_is_required()
		;

		options[ "-min-kmer-count" ]
			.set_description( "Kmer multiplicity above which kmers will be treated as solid" )
			.set_takes_single_value()
			.set_default_value(5)
		;

		options[ "-reads" ]
			.set_description( "Path of fastq file of reads to load." )
			.set_takes_single_value()
			.set_is_required()
		;

		options[ "-min-base-quality" ]
			.set_description( "Minimum base quality; kmers containing bases below this quality will not be counted." )
			.set_takes_single_value()
			.set_default_value(0)
		;

		options[ "-o" ]
			.set_description( "Path of output file." )
			.set_takes_single_value()
			.set_default_value( "-" ) ;
		
		options.declare_group( "Algorithm options" ) ;
		options[ "-max-kmers" ]
			.set_description( "Only read a maximum of this many kmers.  This is useful for testing." )
			.set_takes_single_value()
			.set_default_value( std::numeric_limits< uint32_t >::max() )
		;
		options[ "-threads" ]
			.set_description( "Number of threads to use to load kmers with. " )
			.set_takes_single_value()
			.set_default_value( 1 )
		;

		options.declare_group( "Other options" ) ;
		options[ "-verbose" ]
			.set_description( "Print out details of what is being done." ) ;
	}
} ;
 
struct ClassifyKmerApplication: public appcontext::ApplicationContext
{
public:
	ClassifyKmerApplication( int argc, char** argv ):
		appcontext::ApplicationContext(
			globals::program_name,
			globals::program_version + ", revision " + globals::program_revision,
			std::auto_ptr< appcontext::OptionProcessor >( new AssessPositionOptionProcessor ),
			argc,
			argv,
			"-log"
		)
	{}
	
	void run() {
		try {
			unsafe_process() ;
		}
		catch( genfile::InputError const& e ) {
			ui().logger() << "\nError (" << e.what() <<"): " << e.format_message() << ".\n" ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		}
	}

private:

	void unsafe_process() {
		HashSet kmers ;
		std::size_t const number_of_threads = options().get< std::size_t >( "-threads" ) ;
		uint64_t const multiplicity_threshold = options().get_value< uint64_t >( "-min-kmer-count" ) ;
		std::size_t const max_kmers = options().get< std::size_t >( "-max-kmers" ) ;
		int const base_quality_threshold = options().get< std::size_t >( "-min-base-quality" ) ;
		bool const verbose = options().check( "-verbose" ) ;
		std::size_t k = 0 ;

		{
			boost::timer timer ;
			double start_time = timer.elapsed() ;

			k = load_kmers(
				options().get< std::string >( "-jf" ),
				&kmers,
				number_of_threads,
				multiplicity_threshold,
				max_kmers,
				verbose
			) ;

			double end_time = timer.elapsed() ;
			ui().logger()
				<< "++ Ok, "
				<< kmers.size() << " "
				<< k << "-mers loaded in "
				<< (end_time-start_time)
				<< " seconds:\n" ;
		}

		ui().logger() << "++ Total memory usage is:\n" ;
		ui().logger() << "              (process) : " << std::round(spp::GetProcessMemoryUsed()/1000000.0) << "Mb\n" ;
		ui().logger() << "\n" ;
		{
			ui().logger() << "++ Inspecting reads from \"" << options().get< std::string >( "-reads" ) << "\"...\n" ;
			boost::timer timer ;
			double start_time = timer.elapsed() ;
			statfile::BuiltInTypeStatSink::UniquePtr
				sink = statfile::BuiltInTypeStatSink::open( options().get< std::string >( "-o" ) ) ;

			std::auto_ptr< std::istream >
				fastq = genfile::open_text_file_for_input( options().get< std::string >( "-reads" ) ) ;
		
			std::size_t number_of_reads = process_reads(
				*fastq,
				kmers,
				k,
				base_quality_threshold,
				*sink
			) ;
			double end_time = timer.elapsed() ;
			ui().logger() << "++ Ok, processed " << number_of_reads << " reads in " << (end_time - start_time) << " seconds.\n" ;
		}
	}

	std::size_t load_kmers(
		std::string const& jf_filename,
		HashSet* result,
		std::size_t number_of_threads,
		uint64_t multiplicity_threshold = 0,
		std::size_t max_kmers = std::numeric_limits< std::size_t >::max(),
		bool verbose = false
	) {
		std::ifstream ifs( jf_filename ) ;
		jellyfish::file_header header( ifs ) ;
		std::size_t const k = header.key_len() / 2 ;
		if(verbose) {
			ui().logger()
				<< "++ Loaded header from \"" << jf_filename << "\":\n"
				<< "    size: " << header.size() << "\n"
				<< "    nb_hashes: " << header.nb_hashes() << "\n"
				<< "    key_len: " << header.key_len() << "\n"
				<< "          k: " << k << ".\n" ;
		}

		if( header.format() != binary_dumper::format ) {
			throw genfile::BadArgumentError( "ClassifyKmerApplication::unsafe_process()", "-jf", "Expected a binary-format jellyfish count file." ) ;
		}

		{
			{
				if( number_of_threads < 1 ) {
					throw genfile::BadArgumentError(
						"ClassifyKmerApplication::load_kmers()",
						"number_of_threads",
						"You must supply a value >= 1"
					) ;
				}

				if( (number_of_threads & (number_of_threads - 1) ) != 0 ) {
					throw genfile::BadArgumentError(
						"ClassifyKmerApplication::load_kmers()",
						"number_of_threads",
						"Number of threads must be zero or a power of two."
					) ;
				}

				if( number_of_threads > 32 ) {
					throw genfile::BadArgumentError(
						"ClassifyKmerApplication::load_kmers()",
						"number_of_threads",
						"A maximum of 32 threads are supported."
					) ;
				}
			}
			
			jellyfish::mer_dna::k( k ) ;
			binary_reader reader(ifs, &header);

			{
				std::vector< Queue > queues ;
				std::vector< std::thread > threads ;
				std::atomic< int > quit(0) ;
				ui().logger() << "++ Loading kmers from \"" << jf_filename << "\"\n"
					<< "   ...using " << number_of_threads << " worker threads...\n" ;
			
				for( std::size_t i = 0; i < number_of_threads; ++i ) {
					queues.push_back( Queue( 32768 ) ) ;
					if( verbose ) {
						ui().logger() << "!! Created queue " << i << " at (" << &(queues.back()) << ").\n" ;
					}
				}
				for( std::size_t i = 0; i < number_of_threads; ++i ) {
					threads.push_back(
						std::thread(
							classify_threaded< HashSet >,
							k,
							&(queues[i]),
							result,
							i,
							&quit
						)
					) ;
					if( verbose ) {
						ui().logger() << "!! Created thread " << i << " at (" << &(threads.back()) << ").\n" ;
					}
				}
				
				// read kmers into queues.
				// There is one queue per thread and gets kmers destined for ith
				// hash submap.
				read_into_queues(
					k,
					multiplicity_threshold,
					reader,
					queues,
					*result,
					max_kmers
				) ;
				
				// Wait for it to finish.
				for( std::size_t i = 0; i < number_of_threads; ++i ) {
					while( queues[i].size_approx() > 0 ) {
#if DEBUG
						std::cerr << "++ Queue[" << i << "] size = " << queues[i].size_approx() << ", waiting..." ;
#endif
						std::this_thread::sleep_for( std::chrono::milliseconds(1)) ;
					}
				}

				ui().logger() << "++ Tidying up...\n" ;
				quit = 1 ;
				std::this_thread::sleep_for( std::chrono::milliseconds(1)) ;
				for( std::size_t i = 0; i < number_of_threads; ++i ) {
					threads[i].join() ;
				}
			}
		}
		return k ;
	}
	
	template< typename Iterator >
	void read_into_queues(
		unsigned int const k,
		uint64_t const multiplicity_threshold,
		Iterator it,
		std::vector< Queue >& queues,
		HashSet const& set,
		std::size_t const max_kmers = std::numeric_limits< std::size_t >::max()
	) {
		jellyfish::mer_dna::k( k ) ;
		std::size_t count = 0 ;
		{
			auto progress = ui().get_progress_context( "Loading kmers" ) ;
			while( it.next() && count < max_kmers ) {
				if( it.val() >= multiplicity_threshold ) {
					uint64_t const kmer = it.key().get_bits( 0, 2*k ) ;
					std::size_t const hashvalue = set.hash( kmer ) ;
					std::size_t idx = set.subidx( hashvalue ) ;
#if DEBUG > 1
					std::cerr << "++ kmer: " << genfile::kmer::decode_hash( kmer, k )
						<< ", "
						<< std::hex << kmer << std::dec
						<< ": " << "hashvalue: "
						<< hashvalue << ", idx: " << idx << ".\n" ;
#endif
					std::size_t const queue_index = idx % queues.size() ;
					// Queue& queue = queues[ queue_index ] ;
					Queue& queue = queues[ queue_index ] ;
					while( !queue.try_enqueue( kmer )) {
#if DEBUG > 1
						std::cerr << "-- queue full after " << count << " kmers, sleeping...\n" ;
#endif
						std::this_thread::sleep_for( std::chrono::microseconds(10) ) ;
					}
#if DEBUG > 1
					std::cerr << "++ Wrote " << kmer << " to queue " << queue_index << ".\n" ;
#endif
					progress( ++count ) ;
				}
			}
		}
		ui().logger() << "++ read_into_queue(): Read " << count << " kmers in total.\n" ;
	}
	
	struct ReadResult {
	public:
		ReadResult():
			length(0),
			k(0),
			number_of_kmers_at_threshold(0),
			number_of_solid_kmers_at_threshold(0),
			first_solid_kmer_start(0),
			last_solid_kmer_end(0),
			mean_base_quality(0.0),
			number_of_bases_at_q20(0)
		{}

		ReadResult( ReadResult const& other ):
			length( other.length ),
			k( other.k ),
			number_of_kmers_at_threshold( other.number_of_kmers_at_threshold ),
			number_of_solid_kmers_at_threshold( other.number_of_solid_kmers_at_threshold ),
			first_solid_kmer_start( other.first_solid_kmer_start ),
			last_solid_kmer_end( other.last_solid_kmer_end ),
			mean_base_quality( other.mean_base_quality ),
			number_of_bases_at_q20( other.number_of_bases_at_q20 )
		{}

		ReadResult& operator=( ReadResult const& other ) {
			length = other.length ;
			k = other.k ;
			number_of_kmers_at_threshold = other.number_of_kmers_at_threshold ;
			number_of_solid_kmers_at_threshold = other.number_of_solid_kmers_at_threshold ;
			first_solid_kmer_start = other.first_solid_kmer_start ;
			last_solid_kmer_end = other.last_solid_kmer_end ;
			mean_base_quality = other.mean_base_quality ;
			number_of_bases_at_q20 = other.number_of_bases_at_q20 ;
			return *this ;
		}

	public:
		uint64_t length ;
		uint64_t k ;
		uint64_t number_of_kmers_at_threshold ;
		uint64_t number_of_solid_kmers_at_threshold ;
		uint64_t first_solid_kmer_start ;
		uint64_t last_solid_kmer_end ;
		double mean_base_quality ;
		uint64_t number_of_bases_at_q20 ;
	} ;
	
	std::size_t process_reads(
		std::istream& input,
		HashSet const& kmers,
		std::size_t k,
		uint64_t base_quality_threshold,
		statfile::BuiltInTypeStatSink& output
	) {
		auto progress = ui().get_progress_context( "Examining reads" ) ;

		output
			| "read_id"
			| "read_length"
			| "mean_base_quality"
			| "number_of_bases_at_q20"
			| "kmer_k"
			| "number_of_kmers_at_threshold"
			| "number_of_solid_kmers_at_threshold"
			| "first_solid_kmer_start"
			| "last_solid_kmer_end"
		;
		std::size_t l = 0 ;
		std::size_t count = 0 ;
		std::string line, id, sequence, qualities ;
		while( std::getline( input, line )) {
			switch(l) {
				case 0:
					id = line.substr(1,line.size() ) ;
					break ;
				case 1:
					sequence = line ;
					break ;
				case 2:
					break ;
				case 3:
					qualities = line ;
					break ;
			} ;

			if( (++l) == 4 ) {
				ReadResult const r = process_read(
					id,
					sequence,
					qualities,
					kmers,
					k,
					base_quality_threshold
				) ;

				output
					<< id
					<< r.length
					<< r.mean_base_quality
					<< r.number_of_bases_at_q20
					<< uint64_t(k)
					<< r.number_of_kmers_at_threshold
					<< r.number_of_solid_kmers_at_threshold
					<< r.first_solid_kmer_start
					<< r.last_solid_kmer_end
					<< statfile::end_row() ;
				l = 0 ;
				++count ;
				progress( count ) ;
			}
		}
		return count ;
	}

	ReadResult process_read(
		std::string const& id,
		std::string const& sequence,
		std::string const& qualities,
		HashSet const& kmers,
		std::size_t k,
		int const base_quality_threshold
	) {
		assert( qualities.size() == sequence.size() ) ;
		assert( k <= 31 ) ;
		ReadResult result ;
		result.length = sequence.size() ;
		typedef genfile::kmer::KmerHashIterator< std::string::const_iterator > KmerIterator ;
		KmerIterator kmer_iterator( sequence.begin(), sequence.end(), k ) ;
		int kmer_min_base_quality = 0 ;
		std::size_t kmer_min_base_quality_at = 0 ;
		double sum_of_base_qualities = 0.0 ;
		uint64_t number_of_bases_at_q20 = 0 ;
		bool have_first = false ;
		
		std::size_t i = 0;

		for(
			;
			(i+k) < sequence.size();
			++kmer_iterator, ++i
		) {
			int base_quality = get_quality_from_char(qualities[i]) ;
			sum_of_base_qualities += double(base_quality) ;
			number_of_bases_at_q20 += ( base_quality >= 20 ) ? 1 : 0 ;

			if( kmer_min_base_quality_at == 0 ) {
				compute_min_quality(
					genfile::string_utils::slice( qualities, i, i+k ),
					kmer_min_base_quality,
					kmer_min_base_quality_at
				) ;
			} else {
				--kmer_min_base_quality_at ;
			}
			if( kmer_min_base_quality >= base_quality_threshold ) {
				++(result.number_of_kmers_at_threshold) ;
				uint64_t const hash = kmer_iterator.hash() ;
				uint64_t const reverse_complement_hash = genfile::kmer::reverse_complement( kmer_iterator.hash(), k ) ;
				if( kmers.contains( hash ) || kmers.contains( reverse_complement_hash ) ) {
					if( !have_first ) {
						result.first_solid_kmer_start = i ;
						have_first = true ;
					}
					++(result.number_of_solid_kmers_at_threshold) ;
					result.last_solid_kmer_end = i+k ;
				} else {
#if DEBUG
					std::cerr << "!! kmer not in hash:" << kmer_iterator.to_string() << ":\n"
						<< "    (fwd): " << genfile::kmer::decode_hash( hash, k ) << ": " << hash << "\n"
						<< "    (rev): " << genfile::kmer::decode_hash( reverse_complement_hash, k ) << ".\n" ;
#endif
				}
			}
			if( kmer_iterator.finished() ) {
				break ;
			}
		}
		
		// capture remaining bases for base quality metric
		for(
			;
			i < sequence.size();
			++i
		) {
			int base_quality = get_quality_from_char(qualities[i]) ;
			sum_of_base_qualities += double(base_quality) ;
			number_of_bases_at_q20 += ( base_quality >= 20 ) ? 1 : 0 ;
		}
		
		result.mean_base_quality = sum_of_base_qualities / result.length ;
		result.number_of_bases_at_q20 = number_of_bases_at_q20 ;
		return result ;
	}
	
	inline int get_quality_from_char( char const c ) const {
		return int(c - 33) ;
	}
	
	void compute_min_quality(
		genfile::string_utils::slice const& qualities,
		int& min_quality,
		std::size_t& min_quality_at
	) const {
		min_quality = std::numeric_limits< int >::max() ;
		for( std::size_t i = 0; i < qualities.size(); ++i ) {
			int quality = get_quality_from_char(qualities[i]) ;
			if( quality < min_quality ) {
				min_quality_at = i ;
				min_quality = quality ;
			}
		}
	}
} ;


int main( int argc, char** argv )
{
	std::ios_base::sync_with_stdio( false ) ;
	try {
		ClassifyKmerApplication app( argc, argv ) ;
		app.run() ;
	}
	catch( appcontext::HaltProgramWithReturnCode const& e ) {
		return e.return_code() ;
	}
	return 0 ;
}

